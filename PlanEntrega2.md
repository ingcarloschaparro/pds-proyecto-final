
# ÔøΩÔøΩ PLAN DE TRABAJO T√âCNICO - PROYECTO PLS

## ÔøΩÔøΩ **RESUMEN EJECUTIVO**

El proyecto actual tiene una **arquitectura s√≥lida** con pipeline DVC funcional y datos procesados, pero los **scripts de modelos est√°n vac√≠os** y falta implementaci√≥n de MLflow, dashboard y documentaci√≥n completa. El dataset tiene **182,753 registros** con solo **27% de datos anotados** (PLS), lo que requiere estrategias espec√≠ficas para datos limitados.

---

## üöÄ **FASE 1: MODELOS INICIALES Y BASELINES**

### **1.1 An√°lisis del Estado Actual**
- **Entregable**: Documento de an√°lisis t√©cnico
- **Criterios**: Identificaci√≥n clara de gaps y oportunidades
- **Tareas**:
  - [ ] Analizar distribuci√≥n de datos por fuente (Cochrane: 69%, Trial Summaries: 28%, Pfizer: 1.5%, ClinicalTrials: 0.6%)
  - [ ] Evaluar calidad de anotaciones PLS vs non-PLS
  - [ ] Identificar patrones de longitud y complejidad por fuente

### **1.2 Modelos Base a Implementar**

#### **Clasificador PLS vs non-PLS**
- **Baseline 1**: TF-IDF + Logistic Regression (r√°pido, interpretable)
- **Baseline 2**: DistilBERT fine-tuning (contextual, mejor rendimiento)
- **Estrategia**: Semi-supervisado con datos no etiquetados
- **Entregable**: Scripts funcionales en `src/models/train_classifier.py`
- **Criterios**: F1 macro ‚â• 0.80, matriz de confusi√≥n por fuente

#### **Generador de PLS**
- **Modelo 1**: BART-base (robusto, recursos moderados)
- **Modelo 2**: T5-base (bueno para tareas de resumen)
- **Modelo 3**: BioBART (si est√° disponible, dominio espec√≠fico)
- **Estrategia**: Fine-tuning con LoRA para recursos limitados
- **Entregable**: Scripts funcionales en `src/models/generate_pls.py`
- **Criterios**: Generaci√≥n de res√∫menes 120-250 palabras, legibilidad mejorada

### **1.3 M√©tricas de Evaluaci√≥n**
- **ROUGE-L**: Similitud l√©xica con ground truth
- **METEOR**: Alineaci√≥n sem√°ntica y flexibilidad
- **FKGL**: Flesch-Kincaid Grade Level (legibilidad)
- **BERTScore**: Similitud sem√°ntica contextual
- **Compresi√≥n**: Ratio palabras PLS/original (0.30-0.50 objetivo)

---

## üî¨ **FASE 2: EXPERIMENTOS Y VERSIONADO CON MLFLOW**

### **2.1 Integraci√≥n MLflow + DVC**
- **Arquitectura**: MLflow para experimentos, DVC para datos y modelos
- **Entregable**: Configuraci√≥n `mlflow.yaml` y scripts de logging
- **Tareas**:
  - [ ] Configurar MLflow tracking server local
  - [ ] Integrar logging en scripts de entrenamiento
  - [ ] Definir par√°metros experimentales en `params.yaml`

### **2.2 Par√°metros a Registrar**
```yaml
# Ejemplo de estructura en params.yaml
experiments:
  classifier:
    - model_type: ["tfidf_logreg", "distilbert", "biobert"]
    - learning_rate: [0.001, 0.01, 0.1]
    - batch_size: [16, 32, 64]
  generator:
    - model_name: ["bart-base", "t5-base", "biobart"]
    - max_length: [150, 200, 250]
    - temperature: [0.7, 0.8, 0.9]
```

### **2.3 Convenci√≥n de Nombres**
- **Experimentos**: `{fase}_{modelo}_{fecha}`
  - Ejemplo: `classifier_tfidf_20250115`
- **Runs**: `{modelo}_{parametros}_{timestamp}`
  - Ejemplo: `distilbert_lr0.001_bs32_20250115_143022`
- **Modelos**: `{tipo}_{fuente}_{version}`
  - Ejemplo: `classifier_cochrane_v1.0`

### **2.4 Artefactos a Registrar**
- [ ] Modelos entrenados (formato HuggingFace)
- [ ] M√©tricas de evaluaci√≥n (JSON)
- [ ] Gr√°ficos de entrenamiento (PNG)
- [ ] Ejemplos de predicciones (CSV)
- [ ] Configuraci√≥n de par√°metros (YAML)

---

## üìä **FASE 3: DASHBOARD INTERACTIVO**

### **3.1 Herramienta Seleccionada: Streamlit**
- **Justificaci√≥n**: F√°cil integraci√≥n con MLflow, visualizaciones ricas, despliegue simple
- **Alternativa**: Gradio (si se requiere m√°s simplicidad)

### **3.2 Secciones del Dashboard**

#### **Panel Principal**
- **M√©tricas Globales**: Resumen de rendimiento por modelo
- **Comparaci√≥n de Modelos**: Gr√°ficos de barras y l√≠neas
- **Estado del Pipeline**: Indicadores DVC y MLflow

#### **An√°lisis de Datos**
- **Distribuci√≥n por Fuente**: Gr√°ficos de torta y barras
- **Calidad de Anotaciones**: Estad√≠sticas de PLS vs non-PLS
- **Exploraci√≥n de Textos**: B√∫squeda y visualizaci√≥n de ejemplos

#### **Evaluaci√≥n de Modelos**
- **M√©tricas por Fuente**: ROUGE, METEOR, FKGL estratificados
- **Matrices de Confusi√≥n**: Visualizaci√≥n interactiva
- **Ejemplos de Predicciones**: Comparaci√≥n lado a lado

#### **Gesti√≥n de Experimentos**
- **Historial MLflow**: B√∫squeda y comparaci√≥n de runs
- **Par√°metros √ìptimos**: Identificaci√≥n autom√°tica de mejores configuraciones
- **Exportaci√≥n de Resultados**: Descarga de m√©tricas y modelos

### **3.3 Entregables**
- [ ] Script principal `dashboard.py` en `src/`
- [ ] Componentes modulares en `src/dashboard/`
- [ ] Configuraci√≥n de estilos y temas
- [ ] Documentaci√≥n de uso del dashboard

---

## ÔøΩÔøΩ **FASE 4: DOCUMENTACI√ìN COMPLETA**

### **4.1 README Ampliado**
- [ ] **Instalaci√≥n**: Dependencias, configuraci√≥n DVC/MLflow
- [ ] **Uso R√°pido**: Comandos para ejecutar pipeline completo
- [ ] **Visualizaci√≥n**: Instrucciones para dashboard
- [ ] **Troubleshooting**: Problemas comunes y soluciones
- [ ] **Contribuci√≥n**: Gu√≠a para desarrolladores

### **4.2 Documentaci√≥n de Scripts**
- [ ] **Docstrings en Espa√±ol**: Todos los m√≥dulos y funciones
- [ ] **Ejemplos de Uso**: Casos de uso comunes
- [ ] **Par√°metros**: Descripci√≥n detallada de configuraci√≥n
- [ ] **Salidas**: Formato y ubicaci√≥n de archivos generados

### **4.3 Lineamientos de Estilo**
```python
# Ejemplo de docstring est√°ndar
def entrenar_clasificador(
    datos_entrenamiento: pd.DataFrame,
    parametros: Dict[str, Any]
) -> Tuple[Any, Dict[str, float]]:
    """
    Entrena un clasificador para distinguir entre textos PLS y no-PLS.
    
    Args:
        datos_entrenamiento: DataFrame con columnas 'texto' y 'label'
        parametros: Diccionario con hiperpar√°metros del modelo
        
    Returns:
        Tuple con modelo entrenado y m√©tricas de rendimiento
        
    Raises:
        ValueError: Si los datos no tienen el formato esperado
    """
```

---

## ‚úÖ **FASE 5: REVISI√ìN Y APROBACI√ìN**

### **5.1 Criterios de Aceptaci√≥n por Fase**

#### **Fase 1 - Modelos**
- [ ] Scripts de clasificaci√≥n ejecut√°ndose sin errores
- [ ] Scripts de generaci√≥n produciendo res√∫menes coherentes
- [ ] M√©tricas de evaluaci√≥n calcul√°ndose correctamente
- [ ] Pipeline DVC ejecut√°ndose end-to-end

#### **Fase 2 - MLflow**
- [ ] Experimentos registr√°ndose en MLflow
- [ ] Par√°metros y m√©tricas siendo trackeados
- [ ] Modelos guard√°ndose y version√°ndose
- [ ] Integraci√≥n funcionando con DVC

#### **Fase 3 - Dashboard**
- [ ] Dashboard ejecut√°ndose localmente
- [ ] Todas las secciones funcionando correctamente
- [ ] Visualizaciones mostrando datos reales
- [ ] Integraci√≥n con MLflow operativa

#### **Fase 4 - Documentaci√≥n**
- [ ] README completo y actualizado
- [ ] Docstrings en todos los m√≥dulos
- [ ] Gu√≠as de uso claras y completas
- [ ] Ejemplos ejecutables

### **5.2 Entregables Finales**
- [ ] **Repositorio funcional**: Pipeline completo ejecut√°ndose
- [ ] **Dashboard operativo**: Visualizaci√≥n de resultados
- [ ] **Documentaci√≥n completa**: Gu√≠as de uso y desarrollo
- [ ] **Experimentos versionados**: Historial MLflow con resultados
- [ ] **Modelos entrenados**: Clasificador y generador funcionales

---

## üö® **RIESGOS IDENTIFICADOS Y MITIGACIONES**

### **Riesgo 1: Datos Limitados (27% anotado)**
- **Mitigaci√≥n**: Enfoques semi-supervisados, data augmentation, transfer learning

### **Riesgo 2: Recursos Computacionales**
- **Mitigaci√≥n**: Modelos peque√±os, LoRA, fine-tuning parcial

### **Riesgo 3: Calidad de Anotaciones**
- **Mitigaci√≥n**: Validaci√≥n manual de muestras, filtros de calidad

### **Riesgo 4: Integraci√≥n MLflow-DVC**
- **Mitigaci√≥n**: Pruebas incrementales, documentaci√≥n de configuraci√≥n

---

## üéØ **PR√ìXIMOS PASOS INMEDIATOS**

1. **Validar este plan** con el equipo
2. **Priorizar fases** seg√∫n recursos disponibles
3. **Definir milestones** espec√≠ficos por semana
4. **Asignar responsabilidades** por componente
5. **Iniciar implementaci√≥n** de Fase 1

---
